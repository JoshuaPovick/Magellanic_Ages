{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### Import the usual libraries ###\n",
    "##################################\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import astropy\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table, Column\n",
    "import astropy.coordinates as coord\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.constants as const\n",
    "import astropy.units as u\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 16}) #make plots more readable\n",
    "\n",
    "import palettable as pal\n",
    "\n",
    "import MagellanicStream as ms\n",
    "\n",
    "import dlnpyutils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "###Machine Learning bit import\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "### User defined functions ###\n",
    "##############################\n",
    "\n",
    "#find duplicates in data\n",
    "def dups(data):\n",
    "    list_data = list(data)\n",
    "    keys = []\n",
    "    values = []\n",
    "    not_uniq = list(set([x for x in list_data if list_data.count(x)>1]))\n",
    "    for i in range(len(not_uniq)):\n",
    "        keys.append(not_uniq[i])\n",
    "        values.append(np.where(data==not_uniq[i]))\n",
    "    idx = dict(zip(keys, values))\n",
    "    return not_uniq, idx\n",
    "\n",
    "#calculate absolute mag\n",
    "def absmag(magnitude,distance,par):\n",
    "    ''' !!! Parallax must have units of mas and distances must have units of kpc!!! '''\n",
    "    absm = []\n",
    "    if par == True: #if distance is given as parallax\n",
    "        dist = np.reciprocal(distance)*1000\n",
    "        absm.append(magnitude-5.0*np.log10(dist)+5.0)\n",
    "        absm = np.squeeze(np.array(absm))\n",
    "    else: #if distance is given as distance\n",
    "        absm.append(magnitude-5.0*np.log10(distance*1000)+5.0)\n",
    "        absm = np.squeeze(np.array(absm))\n",
    "    return absm\n",
    "\n",
    "def LMCdisk_cart(ra, dec):\n",
    "    \n",
    "    '''\n",
    "    Calculate the position of stars in the LMC disk plane with \n",
    "    center at the LMC center in cartesian coordinates (x, y).\n",
    "    This also calculates the distance to the individual stars.\n",
    "    \n",
    "    This follows van der Marel and Cioni 2001 \n",
    "    \n",
    "    Input\n",
    "    - ra: right ascension of stars\n",
    "    - dec: declination of stars\n",
    "    \n",
    "    Output\n",
    "    - x_m: x coordinate\n",
    "    - y_m: y coordinate\n",
    "    - dis: distance to LMC star\n",
    "    '''\n",
    "    alph0 = np.radians(82.25) #right ascension of center of LMC\n",
    "    delt0 = np.radians(-69.50) #declination of center of LMC\n",
    "    pa = np.radians(149.23+90.00) #146.37 #position angle of line of nodes\n",
    "    io = np.radians(25.86) #27.81 #inclination of LMC disk\n",
    "    d0 = 49.90 #distance to center of LMC\n",
    "    \n",
    "    #convert to radians\n",
    "    ra = np.radians(ra)\n",
    "    dec = np.radians(dec)\n",
    "    sd = np.sin(delt0)\n",
    "    cd = np.cos(delt0)\n",
    "    \n",
    "    cr = cd*np.cos(dec)*np.cos(ra-alph0)+sd*np.sin(dec)\n",
    "    srcp = -np.cos(dec)*np.sin(ra-alph0)\n",
    "    srsp = cd*np.sin(dec) - sd*np.cos(dec)*np.cos(ra-alph0)\n",
    "    dis = d0*np.cos(io)/(np.cos(io)*cr - np.sin(io)*np.cos(pa)*srsp + np.sin(io)*np.sin(pa)*srcp)\n",
    "    \n",
    "    x_m = dis*srcp\n",
    "    y_m = dis*(np.cos(io)*srsp + np.sin(io)*cr) - d0*np.sin(io)\n",
    "    \n",
    "    return x_m, y_m, dis\n",
    "\n",
    "def sal(MH,aM):\n",
    "    return MH + np.log(0.638*(10**(aM))+0.362)\n",
    "\n",
    "def mad(dat): #median absolute deviation\n",
    "    return np.median(np.absolute(dat - np.median(dat)))\n",
    "\n",
    "#######################\n",
    "### Age of Universe ###\n",
    "#######################\n",
    "\n",
    "'''\n",
    "@article{riess2019large,\n",
    "  title={Large Magellanic Cloud Cepheid Standards Provide a 1\\% Foundation for the Determination of the Hubble Constant and Stronger Evidence for Physics Beyond LambdaCDM},\n",
    "  author={Riess, Adam G and Casertano, Stefano and Yuan, Wenlong and Macri, Lucas M and Scolnic, Dan},\n",
    "  journal={arXiv preprint arXiv:1903.07603},\n",
    "  year={2019}\n",
    "}\n",
    "'''\n",
    "\n",
    "#Value 74.03 \\pm 1.42 (km/s)/Mpc\n",
    "\n",
    "H0 = 74.03*(u.km/u.s)/u.Mpc\n",
    "hertz = H0.to(u.km/u.s/u.pc).to(u.km/u.s/u.km)\n",
    "tage = (1/hertz).to(u.yr)\n",
    "ageU = tage.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### Import fits files ###\n",
    "#########################\n",
    "\n",
    "#PARSEC Isochrones\n",
    "'''\n",
    "isochrone website http://stev.oapd.inaf.it/cgi-bin/cmd\n",
    "Ages used 8 to 10.1 steps 0.15 \n",
    "Metallicity used -2.6 to 0.1 steps 0.099\n",
    "'''\n",
    "\n",
    "parsecall = ascii.read('/Users/joshpovick/Desktop/Research/Magellanic_Ages/logisochrones.dat', \\\n",
    "                    format='basic', delimiter='\\s')\n",
    "\n",
    "rgb = np.where(parsecall['label']==3)\n",
    "parsec = parsecall[rgb]\n",
    "\n",
    "#LMC r13 data\n",
    "lmcr13 = fits.getdata('/Users/joshpovick/Desktop/Research/Magellanic_Ages/lmc_rgbmembers_r13-l33-58672.fits',1)\n",
    "clnr = np.where((lmcr13['FE_H']>-9999.0)&(lmcr13['AK_TARG']>-9999.0)&(lmcr13['LOGG']>0.0)&\n",
    "                (lmcr13['M_H_ERR']>-90.0)&(lmcr13['C_FE']>-9999.0)&(lmcr13['N_FE']>-9999.0))\n",
    "\n",
    "r13 = lmcr13[clnr]\n",
    "\n",
    "#LMC RGB DR16\n",
    "dr16 = fits.getdata('/Users/joshpovick/Desktop/Research/Magellanic_Ages/lmc_rgbmembersdist_dr16beta.fits',1)\n",
    "clnrr13 = np.where((dr16['FE_H']>-9999.0)&(dr16['AK_TARG']>-9999.0)&(dr16['LOGG']>0.0)&\n",
    "                   (dr16['M_H_ERR']>-90.0)&(dr16['C_FE']>-9999.0)&(dr16['N_FE']>-9999.0))\n",
    "\n",
    "clndr16 = dr16[clnrr13]\n",
    "\n",
    "#Diane Feuillet Bayesian Ages\n",
    "pdfout = fits.getdata('/Users/joshpovick/Desktop/Research/Magellanic_Ages/LMC_DR16_all_PDF.fits', 1)\n",
    "clnpdfout = pdfout[ np.where((dr16['FE_H']>-9999.0)&(dr16['AK_TARG']>-9999.0)&(dr16['LOGG']>0.0)&\n",
    "                             (dr16['M_H_ERR']>-90.0)&(dr16['C_FE']>-9999.0)&(dr16['N_FE']>-9999.0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_par = parsec['logAge']\n",
    "x1 = parsec['logTe'] \n",
    "x2 = parsec['Ksmag']\n",
    "x3 = np.log10(parsec['Zini']/0.02)\n",
    "x4 = parsec['logg']\n",
    "\n",
    "X_par =np.array([x1,x2,x3,x4]).T\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_par, y_par, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 12)                60        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 173\n",
      "Trainable params: 173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6448 samples, validate on 1612 samples\n",
      "Epoch 1/150\n",
      "6448/6448 [==============================] - 0s 65us/step - loss: 65.4436 - mse: 65.4436 - mae: 8.0090 - val_loss: 37.1816 - val_mse: 37.1816 - val_mae: 6.0506\n",
      "Epoch 2/150\n",
      "6448/6448 [==============================] - 0s 50us/step - loss: 14.8924 - mse: 14.8924 - mae: 3.4564 - val_loss: 2.6708 - val_mse: 2.6708 - val_mae: 1.3387\n",
      "Epoch 3/150\n",
      "6448/6448 [==============================] - 0s 51us/step - loss: 1.7610 - mse: 1.7610 - mae: 1.0547 - val_loss: 1.5229 - val_mse: 1.5229 - val_mae: 0.9654\n",
      "Epoch 4/150\n",
      "6448/6448 [==============================] - 0s 47us/step - loss: 1.3903 - mse: 1.3903 - mae: 0.9323 - val_loss: 1.2865 - val_mse: 1.2865 - val_mae: 0.8911\n",
      "Epoch 5/150\n",
      "6448/6448 [==============================] - 0s 51us/step - loss: 1.1809 - mse: 1.1809 - mae: 0.8606 - val_loss: 1.1053 - val_mse: 1.1053 - val_mae: 0.8344\n",
      "Epoch 6/150\n",
      "6448/6448 [==============================] - 0s 43us/step - loss: 1.0227 - mse: 1.0227 - mae: 0.8036 - val_loss: 0.9706 - val_mse: 0.9706 - val_mae: 0.7887\n",
      "Epoch 7/150\n",
      "6448/6448 [==============================] - 0s 39us/step - loss: 0.9080 - mse: 0.9080 - mae: 0.7596 - val_loss: 0.8714 - val_mse: 0.8714 - val_mae: 0.7501\n",
      "Epoch 8/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.8256 - mse: 0.8256 - mae: 0.7260 - val_loss: 0.7995 - val_mse: 0.7995 - val_mae: 0.7197\n",
      "Epoch 9/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.7642 - mse: 0.7642 - mae: 0.6999 - val_loss: 0.7431 - val_mse: 0.7431 - val_mae: 0.6951\n",
      "Epoch 10/150\n",
      "6448/6448 [==============================] - 0s 44us/step - loss: 0.7145 - mse: 0.7145 - mae: 0.6764 - val_loss: 0.6950 - val_mse: 0.6950 - val_mae: 0.6773\n",
      "Epoch 11/150\n",
      "6448/6448 [==============================] - 0s 43us/step - loss: 0.6704 - mse: 0.6704 - mae: 0.6561 - val_loss: 0.6482 - val_mse: 0.6482 - val_mae: 0.6511\n",
      "Epoch 12/150\n",
      "6448/6448 [==============================] - 0s 42us/step - loss: 0.6292 - mse: 0.6292 - mae: 0.6344 - val_loss: 0.6047 - val_mse: 0.6047 - val_mae: 0.6248\n",
      "Epoch 13/150\n",
      "6448/6448 [==============================] - 0s 46us/step - loss: 0.5917 - mse: 0.5917 - mae: 0.6116 - val_loss: 0.5668 - val_mse: 0.5668 - val_mae: 0.6023\n",
      "Epoch 14/150\n",
      "6448/6448 [==============================] - 0s 47us/step - loss: 0.5581 - mse: 0.5581 - mae: 0.5937 - val_loss: 0.5342 - val_mse: 0.5342 - val_mae: 0.5822\n",
      "Epoch 15/150\n",
      "6448/6448 [==============================] - 0s 39us/step - loss: 0.5297 - mse: 0.5297 - mae: 0.5772 - val_loss: 0.5072 - val_mse: 0.5072 - val_mae: 0.5654\n",
      "Epoch 16/150\n",
      "6448/6448 [==============================] - 0s 38us/step - loss: 0.5038 - mse: 0.5038 - mae: 0.5631 - val_loss: 0.4828 - val_mse: 0.4828 - val_mae: 0.5533\n",
      "Epoch 17/150\n",
      "6448/6448 [==============================] - 0s 41us/step - loss: 0.4822 - mse: 0.4822 - mae: 0.5509 - val_loss: 0.4620 - val_mse: 0.4620 - val_mae: 0.5420\n",
      "Epoch 18/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.4621 - mse: 0.4621 - mae: 0.5402 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.5375\n",
      "Epoch 19/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.4426 - mse: 0.4426 - mae: 0.5282 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.5163\n",
      "Epoch 20/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.4223 - mse: 0.4223 - mae: 0.5172 - val_loss: 0.4044 - val_mse: 0.4044 - val_mae: 0.5015\n",
      "Epoch 21/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.4012 - mse: 0.4012 - mae: 0.5034 - val_loss: 0.3795 - val_mse: 0.3795 - val_mae: 0.4892\n",
      "Epoch 22/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.3751 - mse: 0.3751 - mae: 0.4874 - val_loss: 0.3516 - val_mse: 0.3516 - val_mae: 0.4727\n",
      "Epoch 23/150\n",
      "6448/6448 [==============================] - 0s 48us/step - loss: 0.3422 - mse: 0.3422 - mae: 0.4658 - val_loss: 0.3101 - val_mse: 0.3101 - val_mae: 0.4414\n",
      "Epoch 24/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.2883 - mse: 0.2883 - mae: 0.4272 - val_loss: 0.2540 - val_mse: 0.2540 - val_mae: 0.4125\n",
      "Epoch 25/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.2222 - mse: 0.2222 - mae: 0.3780 - val_loss: 0.1853 - val_mse: 0.1853 - val_mae: 0.3534\n",
      "Epoch 26/150\n",
      "6448/6448 [==============================] - 0s 38us/step - loss: 0.1561 - mse: 0.1561 - mae: 0.3205 - val_loss: 0.1315 - val_mse: 0.1315 - val_mae: 0.3062\n",
      "Epoch 27/150\n",
      "6448/6448 [==============================] - 0s 41us/step - loss: 0.1002 - mse: 0.1002 - mae: 0.2589 - val_loss: 0.0746 - val_mse: 0.0746 - val_mae: 0.2246\n",
      "Epoch 28/150\n",
      "6448/6448 [==============================] - 0s 59us/step - loss: 0.0572 - mse: 0.0572 - mae: 0.1968 - val_loss: 0.0433 - val_mse: 0.0433 - val_mae: 0.1691\n",
      "Epoch 29/150\n",
      "6448/6448 [==============================] - 0s 48us/step - loss: 0.0299 - mse: 0.0299 - mae: 0.1434 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.1198\n",
      "Epoch 30/150\n",
      "6448/6448 [==============================] - 0s 61us/step - loss: 0.0149 - mse: 0.0149 - mae: 0.1013 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0879\n",
      "Epoch 31/150\n",
      "6448/6448 [==============================] - 0s 60us/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0728 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0631\n",
      "Epoch 32/150\n",
      "6448/6448 [==============================] - 0s 52us/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0567 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0523\n",
      "Epoch 33/150\n",
      "6448/6448 [==============================] - 0s 44us/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0514 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0501\n",
      "Epoch 34/150\n",
      "6448/6448 [==============================] - 0s 38us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0487 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0507\n",
      "Epoch 35/150\n",
      "6448/6448 [==============================] - 0s 41us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0478 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0484\n",
      "Epoch 36/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0478 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0494\n",
      "Epoch 37/150\n",
      "6448/6448 [==============================] - 0s 35us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0475 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0479\n",
      "Epoch 38/150\n",
      "6448/6448 [==============================] - 0s 35us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0474 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0487\n",
      "Epoch 39/150\n",
      "6448/6448 [==============================] - 0s 35us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0477 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0484\n",
      "Epoch 40/150\n",
      "6448/6448 [==============================] - 0s 35us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0480 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0493\n",
      "Epoch 41/150\n",
      "6448/6448 [==============================] - 0s 34us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0479 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0489\n",
      "Epoch 42/150\n",
      "6448/6448 [==============================] - 0s 34us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0475 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0478\n",
      "Epoch 43/150\n",
      "6448/6448 [==============================] - 0s 35us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0477 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0477\n",
      "Epoch 44/150\n",
      "6448/6448 [==============================] - 0s 34us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0476 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0476\n",
      "Epoch 45/150\n",
      "6448/6448 [==============================] - 0s 34us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0479 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0497\n",
      "Epoch 46/150\n",
      "6448/6448 [==============================] - 0s 34us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0483 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0486\n",
      "Epoch 47/150\n",
      "6448/6448 [==============================] - 0s 37us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0486 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0489\n",
      "Epoch 48/150\n",
      "6448/6448 [==============================] - 0s 39us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0481 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0475\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6448/6448 [==============================] - 0s 36us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0475 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0475\n",
      "Epoch 50/150\n",
      "6448/6448 [==============================] - 0s 41us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0476 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0482\n",
      "Epoch 51/150\n",
      "6448/6448 [==============================] - 0s 65us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0479 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0477\n",
      "Epoch 52/150\n",
      "6448/6448 [==============================] - 0s 31us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0489 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0489\n",
      "Epoch 53/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0487 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0488\n",
      "Epoch 54/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0478 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0490\n",
      "Epoch 55/150\n",
      "6448/6448 [==============================] - 0s 31us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0482 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0566\n",
      "Epoch 56/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0483 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0478\n",
      "Epoch 57/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0487 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0480\n",
      "Epoch 58/150\n",
      "6448/6448 [==============================] - 0s 31us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0484 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0481\n",
      "Epoch 59/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0482 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0476\n",
      "Epoch 60/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0480 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0515\n",
      "Epoch 61/150\n",
      "6448/6448 [==============================] - 0s 31us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0479 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0476\n",
      "Epoch 62/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0491 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0494\n",
      "Epoch 63/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0482 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0478\n",
      "Epoch 64/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0478 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0508\n",
      "Epoch 65/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0489 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0497\n",
      "Epoch 66/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0482 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0478\n",
      "Epoch 67/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0474 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0477\n",
      "Epoch 68/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0497 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0486\n",
      "Epoch 69/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0496 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0537\n",
      "Epoch 70/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0489 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0487\n",
      "Epoch 71/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0481 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0474\n",
      "Epoch 72/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0478 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0475\n",
      "Epoch 73/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0503 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0498\n",
      "Epoch 74/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0488 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0475\n",
      "Epoch 75/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0482 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0479\n",
      "Epoch 76/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0482 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0479\n",
      "Epoch 77/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0476 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0482\n",
      "Epoch 78/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0480 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0476\n",
      "Epoch 79/150\n",
      "6448/6448 [==============================] - 0s 29us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0487 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0492\n",
      "Epoch 80/150\n",
      "6448/6448 [==============================] - 0s 38us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0476 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0474\n",
      "Epoch 81/150\n",
      "6448/6448 [==============================] - 0s 39us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0482 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0475\n",
      "Epoch 82/150\n",
      "6448/6448 [==============================] - 0s 39us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0486 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0480\n",
      "Epoch 83/150\n",
      "6448/6448 [==============================] - 0s 36us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0481 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0477\n",
      "Epoch 84/150\n",
      "6448/6448 [==============================] - 0s 31us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0491 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0513\n",
      "Epoch 85/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0480 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0474\n",
      "Epoch 86/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0492 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0476\n",
      "Epoch 87/150\n",
      "6448/6448 [==============================] - 0s 35us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0487 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0482\n",
      "Epoch 88/150\n",
      "6448/6448 [==============================] - 0s 36us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0480 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0479\n",
      "Epoch 89/150\n",
      "6448/6448 [==============================] - 0s 58us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0479 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0485\n",
      "Epoch 90/150\n",
      "6448/6448 [==============================] - 0s 31us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0482 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0478\n",
      "Epoch 91/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0484 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0474\n",
      "Epoch 92/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0485 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0478\n",
      "Epoch 93/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0488 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0491\n",
      "Epoch 94/150\n",
      "6448/6448 [==============================] - 0s 61us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0484 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0537\n",
      "Epoch 95/150\n",
      "6448/6448 [==============================] - 0s 31us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0482 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0478\n",
      "Epoch 96/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0485 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0509\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6448/6448 [==============================] - 0s 48us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0488 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0483\n",
      "Epoch 98/150\n",
      "6448/6448 [==============================] - 0s 34us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0475 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0493\n",
      "Epoch 99/150\n",
      "6448/6448 [==============================] - 0s 41us/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0497 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0495\n",
      "Epoch 100/150\n",
      "6448/6448 [==============================] - 0s 39us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0486 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0554\n",
      "Epoch 101/150\n",
      "6448/6448 [==============================] - 0s 32us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0479 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0502\n",
      "Epoch 102/150\n",
      "6448/6448 [==============================] - 0s 30us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0482 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0477\n",
      "Epoch 103/150\n",
      "6448/6448 [==============================] - 0s 49us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0479 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0504\n",
      "Epoch 104/150\n",
      "6448/6448 [==============================] - 0s 57us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0478 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0509\n",
      "Epoch 105/150\n",
      "6448/6448 [==============================] - 0s 52us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0482 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0492\n",
      "Epoch 106/150\n",
      "6448/6448 [==============================] - 0s 34us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0482 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0483\n",
      "Epoch 107/150\n",
      "6448/6448 [==============================] - 0s 60us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0487 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0539\n",
      "Epoch 108/150\n",
      "6448/6448 [==============================] - 0s 54us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0490 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0483\n",
      "Epoch 109/150\n",
      "6448/6448 [==============================] - 0s 52us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0483 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0520\n",
      "Epoch 110/150\n",
      "6448/6448 [==============================] - 0s 35us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0488 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0474\n",
      "Epoch 111/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0474 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0495\n",
      "Epoch 112/150\n",
      "6448/6448 [==============================] - 0s 45us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0480 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0472\n",
      "Epoch 113/150\n",
      "6448/6448 [==============================] - 0s 48us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0479 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0476\n",
      "Epoch 114/150\n",
      "6448/6448 [==============================] - 0s 50us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0473 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0472\n",
      "Epoch 115/150\n",
      "6448/6448 [==============================] - 0s 47us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0491 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0483\n",
      "Epoch 116/150\n",
      "6448/6448 [==============================] - 0s 44us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0477 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0477\n",
      "Epoch 117/150\n",
      "6448/6448 [==============================] - 0s 38us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0485 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0511\n",
      "Epoch 118/150\n",
      "6448/6448 [==============================] - 0s 37us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0478 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0475\n",
      "Epoch 119/150\n",
      "6448/6448 [==============================] - 0s 50us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0483 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0483\n",
      "Epoch 120/150\n",
      "6448/6448 [==============================] - 0s 39us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0486 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0474\n",
      "Epoch 121/150\n",
      "6448/6448 [==============================] - 1s 79us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0481 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0497\n",
      "Epoch 122/150\n",
      "6448/6448 [==============================] - 0s 58us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0482 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0477\n",
      "Epoch 123/150\n",
      "6448/6448 [==============================] - 0s 42us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0475 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0490\n",
      "Epoch 124/150\n",
      "6448/6448 [==============================] - 0s 38us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0488 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0483\n",
      "Epoch 125/150\n",
      "6448/6448 [==============================] - 0s 48us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0482 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0484\n",
      "Epoch 126/150\n",
      "6448/6448 [==============================] - 0s 38us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0482 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0489\n",
      "Epoch 127/150\n",
      "6448/6448 [==============================] - 0s 38us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0479 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0492\n",
      "Epoch 128/150\n",
      "6448/6448 [==============================] - 1s 94us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0480 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0497\n",
      "Epoch 129/150\n",
      "6448/6448 [==============================] - 1s 78us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0477 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0477\n",
      "Epoch 130/150\n",
      "6448/6448 [==============================] - 0s 61us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0486 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0478\n",
      "Epoch 131/150\n",
      "6448/6448 [==============================] - 0s 45us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0483 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0470\n",
      "Epoch 132/150\n",
      "6448/6448 [==============================] - 0s 44us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0477 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0482\n",
      "Epoch 133/150\n",
      "6448/6448 [==============================] - 0s 61us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0478 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0479\n",
      "Epoch 134/150\n",
      "6448/6448 [==============================] - 0s 49us/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0493 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0525\n",
      "Epoch 135/150\n",
      "6448/6448 [==============================] - 0s 51us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0480 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0496\n",
      "Epoch 136/150\n",
      "6448/6448 [==============================] - 0s 62us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0477 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0475\n",
      "Epoch 137/150\n",
      "6448/6448 [==============================] - 0s 49us/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0492 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0530\n",
      "Epoch 138/150\n",
      "6448/6448 [==============================] - 0s 59us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0485 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0475\n",
      "Epoch 139/150\n",
      "6448/6448 [==============================] - 0s 70us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0487 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0478\n",
      "Epoch 140/150\n",
      "6448/6448 [==============================] - 0s 59us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0474 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0474\n",
      "Epoch 141/150\n",
      "6448/6448 [==============================] - 0s 42us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0473 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0479\n",
      "Epoch 142/150\n",
      "6448/6448 [==============================] - 0s 44us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0482 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0477\n",
      "Epoch 143/150\n",
      "6448/6448 [==============================] - 0s 39us/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0484 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0482\n",
      "Epoch 144/150\n",
      "6448/6448 [==============================] - 0s 42us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0478 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0472\n",
      "Epoch 145/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6448/6448 [==============================] - 0s 46us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0481 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0506\n",
      "Epoch 146/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0476 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0483\n",
      "Epoch 147/150\n",
      "6448/6448 [==============================] - 0s 40us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0483 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0472\n",
      "Epoch 148/150\n",
      "6448/6448 [==============================] - 0s 41us/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0477 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0499\n",
      "Epoch 149/150\n",
      "6448/6448 [==============================] - 0s 47us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0477 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0469\n",
      "Epoch 150/150\n",
      "6448/6448 [==============================] - 0s 52us/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0480 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0523\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mse', 'val_mae', 'loss', 'mse', 'mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xnew = np.array([[40, 0, 26, 9000, 8000]])\n",
    "# X_test = scaler_x.transform(X_test)\n",
    "y_new = model.predict(X_test)\n",
    "#invert normalize\n",
    "# y_new = scaler_y.inverse_transform(y_new) \n",
    "# Xnew = scaler_x.inverse_transform(Xnew)\n",
    "# print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))\n",
    "\n",
    "plt.hist(y_new-y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-beefcf227a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creating the Confusion Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "# Creating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.,    0.,    0.,    0.,    0., 3225.,    0.,    0.,    0.,\n",
       "           0.]), array([0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3, 1.4, 1.5],\n",
       "       dtype=float32), <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Randomly Generated Weights: \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (4,8060) and (3,1) not aligned: 8060 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-4cb380b6b8b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#training taking place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ending Weights After Training: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-4cb380b6b8b7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_inputs, training_outputs, training_iterations)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#siphon the training data via  the neuron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#computing error rate for back-propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-4cb380b6b8b7>\u001b[0m in \u001b[0;36mthink\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynaptic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,8060) and (3,1) not aligned: 8060 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # seeding for random number generation\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
    "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        #applying the sigmoid function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        #computing derivative to the Sigmoid function\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, training_inputs, training_outputs, training_iterations):\n",
    "        \n",
    "        #training the model to make accurate predictions while adjusting weights continually\n",
    "        for iteration in range(training_iterations):\n",
    "            #siphon the training data via  the neuron\n",
    "            output = self.think(training_inputs)\n",
    "\n",
    "            #computing error rate for back-propagation\n",
    "            error = training_outputs - output\n",
    "            \n",
    "            #performing weight adjustments\n",
    "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "\n",
    "            self.synaptic_weights += adjustments\n",
    "\n",
    "    def think(self, inputs):\n",
    "        #passing the inputs via the neuron to get output   \n",
    "        #converting values to floats\n",
    "        \n",
    "        inputs = inputs.astype(float)\n",
    "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
    "        return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #initializing the neuron class\n",
    "    neural_network = NeuralNetwork()\n",
    "\n",
    "    print(\"Beginning Randomly Generated Weights: \")\n",
    "    print(neural_network.synaptic_weights)\n",
    "\n",
    "    #training data consisting of 4 examples--3 input values and 1 output\n",
    "    training_inputs = X_train.T #np.array([[0,0,1],\n",
    "                                #[1,1,1],\n",
    "                                #[1,0,1],\n",
    "                                #[0,1,1]])\n",
    "\n",
    "    training_outputs = y_train #np.array([[0,1,1,0]]).T\n",
    "\n",
    "    #training taking place\n",
    "    neural_network.train(training_inputs, training_outputs, 15000)\n",
    "\n",
    "    print(\"Ending Weights After Training: \")\n",
    "    print(neural_network.synaptic_weights)\n",
    "\n",
    "    user_input_one = str(input(\"User Input One: \"))\n",
    "    user_input_two = str(input(\"User Input Two: \"))\n",
    "    user_input_three = str(input(\"User Input Three: \"))\n",
    "    \n",
    "    print(\"Considering New Situation: \", user_input_one, user_input_two, user_input_three)\n",
    "    print(\"New Output data: \")\n",
    "    print(neural_network.think(np.array([user_input_one, user_input_two, user_input_three])))\n",
    "    print(\"Wow, we did it!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_age = []\n",
    "for i in range(len(r13)):\n",
    "    euclid = []\n",
    "    for j in range(len(parsec)):\n",
    "        euclid.append(np.sqrt((np.log10(r13['TEFF'][i])-parsec['logTe'][j])**2+\n",
    "                              (r13['K'][i]-parsec['Ksmag'][j])**2+\n",
    "                              (r13['FE_H'][i]-np.log10(parsec['Zini'][j]/0.02))**2+\n",
    "                              (r13['LOGG'][i]-parsec['logg'][j])**2))\n",
    "    idx = np.asarray(euclid).argmin()\n",
    "    nn_age.append(parsec['logAge'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.,    0.,    0.,    0.,    0., 2427.,    0.,    0.,    0.,\n",
       "           0.]),\n",
       " array([ 9.6,  9.7,  9.8,  9.9, 10. , 10.1, 10.2, 10.3, 10.4, 10.5, 10.6]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(nn_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
